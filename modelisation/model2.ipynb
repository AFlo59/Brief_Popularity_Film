{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures, RobustScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import xgboost \n",
    "from sklearn import set_config\n",
    "set_config(transform_output=\"pandas\")\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from db.database_mysql import engine\n",
    "\n",
    "df = pd.read_sql_query('''SELECT jp.raw_title, \n",
    "        YEAR(jp.date) AS year, \n",
    "        MONTH(jp.date) AS month, \n",
    "        DAY(jp.date) AS day, \n",
    "        im.director, im.date,im.casting, im.distributor, im.genre, jp.country, jp.duration, jp.first_day, jp.first_week, jp.first_weekend, jp.hebdo_rank, \n",
    "jp.total_spectator, jp.copies, im.rating_press, im.budget, im.lang, im.award \n",
    "FROM films_jp as jp\n",
    "LEFT JOIN films_imdb im ON im.id_jp = jp.id \n",
    "where im.id_jp is not null and im.date = jp.date\n",
    "order by jp.first_week desc''', engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATION DES SCORES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from modelisation.functions import *\n",
    "\n",
    "clone = df.copy()\n",
    "calculate_director_scores(clone)\n",
    "calculate_distributor_scores(clone)\n",
    "calculate_actor_scores(clone)\n",
    "calculate_year_scores(clone)\n",
    "calculate_country_scores(clone)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_title</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>director</th>\n",
       "      <th>date</th>\n",
       "      <th>casting</th>\n",
       "      <th>distributor</th>\n",
       "      <th>genre</th>\n",
       "      <th>country</th>\n",
       "      <th>duration</th>\n",
       "      <th>first_day</th>\n",
       "      <th>first_week</th>\n",
       "      <th>first_weekend</th>\n",
       "      <th>hebdo_rank</th>\n",
       "      <th>total_spectator</th>\n",
       "      <th>copies</th>\n",
       "      <th>rating_press</th>\n",
       "      <th>budget</th>\n",
       "      <th>lang</th>\n",
       "      <th>award</th>\n",
       "      <th>season</th>\n",
       "      <th>entree_annee</th>\n",
       "      <th>month_name</th>\n",
       "      <th>is_holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bienvenue chez les Ch'tis</td>\n",
       "      <td>2008</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>\"dany boon\"</td>\n",
       "      <td>2008-02-27</td>\n",
       "      <td>[\"kad merad\", \"dany boon\", \"zoe felix\"]</td>\n",
       "      <td>[\"pathe renn productions\", \"hirsch\", \"les prod...</td>\n",
       "      <td>[\"comedie\", \"romantique\"]</td>\n",
       "      <td>france</td>\n",
       "      <td>6360</td>\n",
       "      <td>558359</td>\n",
       "      <td>4378720</td>\n",
       "      <td>3586497</td>\n",
       "      <td>1</td>\n",
       "      <td>20489303</td>\n",
       "      <td>793</td>\n",
       "      <td>7.1</td>\n",
       "      <td>11000000</td>\n",
       "      <td>[\"francais\"]</td>\n",
       "      <td>5</td>\n",
       "      <td>winter</td>\n",
       "      <td>190.3</td>\n",
       "      <td>february</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   raw_title  year  month  day     director        date  \\\n",
       "0  Bienvenue chez les Ch'tis  2008      2   27  \"dany boon\"  2008-02-27   \n",
       "\n",
       "                                   casting  \\\n",
       "0  [\"kad merad\", \"dany boon\", \"zoe felix\"]   \n",
       "\n",
       "                                         distributor  \\\n",
       "0  [\"pathe renn productions\", \"hirsch\", \"les prod...   \n",
       "\n",
       "                       genre country  duration  first_day  first_week  \\\n",
       "0  [\"comedie\", \"romantique\"]  france      6360     558359     4378720   \n",
       "\n",
       "   first_weekend  hebdo_rank  total_spectator  copies  rating_press    budget  \\\n",
       "0        3586497           1         20489303     793           7.1  11000000   \n",
       "\n",
       "           lang  award  season  entree_annee month_name  is_holiday  \n",
       "0  [\"francais\"]      5  winter         190.3   february           0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from modelisation.functions import *\n",
    "\n",
    "entree_transformer = FunctionTransformer(classify_entrees_year, kw_args={'column' : 'year'})\n",
    "season_transformer = FunctionTransformer(classify_season,  kw_args={'column' : 'month'})\n",
    "month_transformer = FunctionTransformer(classify_month_name,  kw_args={'column' : 'month'})\n",
    "holiday_transformer = FunctionTransformer(is_holiday)\n",
    "drop_transformer = FunctionTransformer(drop_temp)\n",
    "\n",
    "pipe_scores = Pipeline([\n",
    "  ('season_dict' , make_pipeline(season_transformer)),\n",
    "  ('entree_dict' , make_pipeline(entree_transformer)),\n",
    "  ('month_dict' , make_pipeline(month_transformer)),\n",
    "  ('holiday_dict' , make_pipeline(holiday_transformer)),\n",
    "  #('drop_dict' , make_pipeline(drop_transformer))\n",
    "])\n",
    "\n",
    "scores = df.copy()\n",
    "scores = pipe_scores.fit_transform(scores)\n",
    "scores.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>director</th>\n",
       "      <th>distributor</th>\n",
       "      <th>casting</th>\n",
       "      <th>copies</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>\"david schickele\"</td>\n",
       "      <td>[\"american film institute afi\", \"bushman co\"]</td>\n",
       "      <td>[\"paul eyam nzie okpokam\", \"mike slye\", \"elain...</td>\n",
       "      <td>14</td>\n",
       "      <td>4380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day           director  \\\n",
       "0  2024      4   24  \"david schickele\"   \n",
       "\n",
       "                                     distributor  \\\n",
       "0  [\"american film institute afi\", \"bushman co\"]   \n",
       "\n",
       "                                             casting  copies  duration  \n",
       "0  [\"paul eyam nzie okpokam\", \"mike slye\", \"elain...      14      4380  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "film = pd.read_sql_query('''SELECT \n",
    "                              YEAR(date) AS year, \n",
    "                              MONTH(date) AS month, \n",
    "                              DAY(date) AS day, \n",
    "                              director, distributor, casting, copies, duration\n",
    "                            FROM functionalities_filmscrap\n",
    "                            LIMIT 1\n",
    "                         ''', engine)\n",
    "film"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def convert_entrees_year(df, column):\n",
    "  print('convert_entrees_year', df.iloc[0][column])\n",
    "  scores = load_file('year_scores')\n",
    "  found = scores.loc[scores[column] == df.iloc[0][column]]\n",
    "  df['year_combined_score'] = found.iloc[0]['year_combined_score']\n",
    "  return df\n",
    "  \n",
    "def convert_director(df, column):\n",
    "  print('convert_director',)\n",
    "  scores = load_file('director_scores')\n",
    "  try:\n",
    "    val = []\n",
    "    for index, row in df.iterrows():\n",
    "      found = scores.loc[scores[column] == df.iloc[index][column]]\n",
    "      val.append(found.iloc[0]['director_combined_score'])\n",
    "  except Exception:\n",
    "    df['director_combined_score'] = 0\n",
    "  \n",
    "  df['director_combined_score'] = pd.Series(val)\n",
    "  return df\n",
    "\n",
    "def convert_actor(df, column):\n",
    "  print('convert_actor')\n",
    "  scores = load_file('actor_scores')\n",
    "\n",
    "  \n",
    "  df['actor_combined_score'] = 0\n",
    "  \n",
    "  val = []\n",
    "  for index, row in df.iterrows():\n",
    "    df_actors = json.loads(df.iloc[index][column])\n",
    "    sum = 0\n",
    "    for actor in df_actors:      \n",
    "      found = scores.loc[scores['actor'] == actor]\n",
    "      if found.shape[0] != 0:\n",
    "        sum += found.iloc[0]['actor_combined_score']\n",
    "\n",
    "    val.append(sum)\n",
    "\n",
    "  df['actor_combined_score'] = pd.Series(val)\n",
    "  return df\n",
    "\n",
    "def convert_distributor(df, column):\n",
    "  print('convert_distributor')\n",
    "  scores = load_file('distributor_scores')\n",
    "\n",
    "  \n",
    "  df['distributor_combined_score'] = 0\n",
    "  \n",
    "  val = []\n",
    "  for index, row in df.iterrows():\n",
    "    df_distributors = json.loads(df.iloc[index][column])\n",
    "    sum = 0\n",
    "    for distributor in df_distributors:      \n",
    "      found = scores.loc[scores['distributor'] == distributor]\n",
    "      if found.shape[0] != 0:\n",
    "        sum += found.iloc[0]['distributor_combined_score']\n",
    "\n",
    "    val.append(sum)\n",
    "\n",
    "  df['distributor_combined_score'] = pd.Series(val)\n",
    "  return df\n",
    "\n",
    "\n",
    "entree_converter = FunctionTransformer(convert_entrees_year, kw_args={'column' : 'year'})\n",
    "season_converter = FunctionTransformer(classify_season,  kw_args={'column' : 'month'})\n",
    "month_converter = FunctionTransformer(classify_month_name,  kw_args={'column' : 'month'})\n",
    "holiday_converter = FunctionTransformer(is_holiday)\n",
    "director_converter = FunctionTransformer(convert_director, kw_args={'column' : 'director'})\n",
    "actor_converter = FunctionTransformer(convert_actor, kw_args={'column' : 'casting'})\n",
    "distributor_converter = FunctionTransformer(convert_distributor, kw_args={'column' : 'distributor'})\n",
    "drop = FunctionTransformer(drop_temp)\n",
    "\n",
    "pipe = Pipeline([\n",
    "  ('season_converter' , make_pipeline(season_converter)),\n",
    "  ('entree_converter' , make_pipeline(entree_converter)),\n",
    "  ('month_converter' , make_pipeline(month_converter)),\n",
    "  ('holiday_converter' , make_pipeline(holiday_converter)),\n",
    "  ('director_converter' , make_pipeline(director_converter)),\n",
    "  ('actor_converter' , make_pipeline(actor_converter)),\n",
    "  ('distributor_converter' , make_pipeline(distributor_converter)),\n",
    "  #('drop' , make_pipeline(drop)),\n",
    "])\n",
    "\n",
    "# t = df.copy()\n",
    "# pipe.fit_transform(t)['distributor_combined_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert_entrees_year 1995\n",
      "convert_director\n",
      "convert_actor\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 35\u001b[0m\n\u001b[1;32m     27\u001b[0m model \u001b[38;5;241m=\u001b[39m make_pipeline(\n\u001b[1;32m     28\u001b[0m             pipe,\n\u001b[1;32m     29\u001b[0m             make_pipeline(drop),\n\u001b[1;32m     30\u001b[0m             \u001b[38;5;66;03m#preprocessing,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m             \u001b[38;5;66;03m#xgboost.XGBRegressor(enable_categorical=True, n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m         )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#model.fit(X_train, y_train)\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m p\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m#xgboost.plot_importance(model[-1], max_num_features=20)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:905\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    903\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 905\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:905\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    903\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 905\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/pipeline.py:905\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    903\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[0;32m--> 905\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:267\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \n\u001b[1;32m    255\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    266\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 267\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkw_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    268\u001b[0m output_config \u001b[38;5;241m=\u001b[39m _get_output_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(out, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# check the consistency between the column provided by `transform` and\u001b[39;00m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;66;03m# the the column names provided by `get_feature_names_out`.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:394\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[0;32m--> 394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkw_args\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[88], line 34\u001b[0m, in \u001b[0;36mconvert_actor\u001b[0;34m(df, column)\u001b[0m\n\u001b[1;32m     32\u001b[0m val \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 34\u001b[0m   df_actors \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m[column])\n\u001b[1;32m     35\u001b[0m   \u001b[38;5;28msum\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     36\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m actor \u001b[38;5;129;01min\u001b[39;00m df_actors:      \n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1189\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj)\n\u001b[1;32m   1190\u001b[0m maybe_callable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001b[0;32m-> 1191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1752\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot index by location index with a non-integer key\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[0;32m-> 1752\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_ixs(key, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/Documents/Simplon/film_predict/.venv/lib/python3.11/site-packages/pandas/core/indexing.py:1685\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1683\u001b[0m len_axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_axis(axis))\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m len_axis \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m-\u001b[39mlen_axis:\n\u001b[0;32m-> 1685\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle positional indexer is out-of-bounds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df_clean = df.copy() #df.drop(columns=['raw_title', 'total_spectator', 'first_day', 'first_weekend', 'hebdo_rank', 'total_spectator', 'rating_press', 'award', 'lang'])\n",
    "\n",
    "X = df_clean.drop(['first_week'], axis=1)\n",
    "y = df_clean.first_week\n",
    "\n",
    "#display(X.info())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, train_size=0.85, random_state=42)\n",
    "\n",
    "num_col = list(X.select_dtypes(include=[float,int]).columns)\n",
    "cat_col = list(X.select_dtypes(include=[object]).columns)\n",
    "\n",
    "onehotscale_pipeline = make_pipeline(OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "scale_pipeline = make_pipeline(RobustScaler(with_centering=False))\n",
    "\n",
    "preprocessing = ColumnTransformer(\n",
    "    transformers=[\n",
    "        #('categorical', onehotscale_pipeline, ['country', 'season', 'month_name']),\n",
    "        ('numerical', scale_pipeline, ['year_combined_score', 'director_combined_score', 'actor_combined_score', 'distributor_combined_score'])\n",
    "    ],\n",
    "    remainder='passthrough',\n",
    "    verbose_feature_names_out=False\n",
    ")\n",
    "\n",
    "polyscale_pipeline = make_pipeline(PolynomialFeatures(2))\n",
    "\n",
    "model = make_pipeline(\n",
    "            pipe,\n",
    "            make_pipeline(drop),\n",
    "            #preprocessing,\n",
    "            #xgboost.XGBRegressor(enable_categorical=True, n_estimators=1000, max_depth=7, eta=0.1, subsample=0.7, colsample_bytree=0.8)\n",
    "        )\n",
    "\n",
    "#model.fit(X_train, y_train)\n",
    "p = model.transform(X_train)\n",
    "p.head(5)\n",
    "\n",
    "#xgboost.plot_importance(model[-1], max_num_features=20)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
